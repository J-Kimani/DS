{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tz5E_upG0av"
      },
      "source": [
        "tokenization is a process of splitting text into meaningful segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oseihUG_kd1Y"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwxQaha2JycM"
      },
      "source": [
        "basic english word tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating a blank language object\n",
        "nlp = spacy.blank(\"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISTwisLYMxi_",
        "outputId": "0d001bde-59db-41ec-ede6-7ad5006e07a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"\n",
            "Let\n",
            "'s\n",
            "go\n",
            "to\n",
            "N.Y.\n",
            "!\n",
            "\"\n"
          ]
        }
      ],
      "source": [
        "doc = nlp('''\"Let's go to N.Y.!\"''')\n",
        "\n",
        "for token in doc:\n",
        "  print(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqGMZBN-Jts5",
        "outputId": "4bdb10a8-6519-4981-efd2-07a8c36d5107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "of\n",
            "mumbai\n",
            "as\n",
            "it\n",
            "costs\n",
            "only\n",
            "2\n",
            "$\n",
            "per\n",
            "plate\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate.\")\n",
        "for token in doc:\n",
        "  print(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0U0ZOc4LPBx",
        "outputId": "c6e5d439-9780-4806-d6ef-f9f42f2ca778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dr."
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# using index to grab tokens\n",
        "doc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrCXelSILk1h",
        "outputId": "b8758b16-fefa-4c4c-f5b1-6b906c73901f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "of"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AynfWrCZLngm",
        "outputId": "253d594e-3ca3-4510-ed58-a5089675fdd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvs8-kxWMeb7",
        "outputId": "58f932e9-92f0-41d2-a34a-643d3a8cecde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRuX48sdNhLI",
        "outputId": "ea5924b9-0186-4f29-caa2-cbf10f2daf15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojfeUndxOEtU",
        "outputId": "b3ad3d51-e9ae-44d2-b396-070a75dc96de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEAaL98fOJ0G",
        "outputId": "1be56b6a-225d-46f6-8621-9f9556fc1cf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Strange loves pav bhaji"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc[1:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7_k_9gVN5_q"
      },
      "source": [
        "# span object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFwxT_HGNkNm",
        "outputId": "8eca036c-95bb-406d-9ec7-b425e2860c42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "span = doc[1:5]\n",
        "type(span)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSGpFbyeOjRH"
      },
      "source": [
        "token attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5qCbp_ZHOT8F"
      },
      "outputs": [],
      "source": [
        "doc = nlp(\"Tony gave two $ to Peter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CsnkV8aPWr4",
        "outputId": "4613e158-0163-49b8-a9f2-a2d57429163f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Tony"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token0 = doc[0]\n",
        "token0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duluC2TUPlTI",
        "outputId": "602999ef-ed62-4b90-b1e6-62d6011e1a74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(token0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Le_-q-MPaH8",
        "outputId": "d6b6c6d9-7520-4a43-edea-fcb55e3e28d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " 'ancestors',\n",
              " 'check_flag',\n",
              " 'children',\n",
              " 'cluster',\n",
              " 'conjuncts',\n",
              " 'dep',\n",
              " 'dep_',\n",
              " 'doc',\n",
              " 'ent_id',\n",
              " 'ent_id_',\n",
              " 'ent_iob',\n",
              " 'ent_iob_',\n",
              " 'ent_kb_id',\n",
              " 'ent_kb_id_',\n",
              " 'ent_type',\n",
              " 'ent_type_',\n",
              " 'get_extension',\n",
              " 'has_dep',\n",
              " 'has_extension',\n",
              " 'has_head',\n",
              " 'has_morph',\n",
              " 'has_vector',\n",
              " 'head',\n",
              " 'i',\n",
              " 'idx',\n",
              " 'iob_strings',\n",
              " 'is_alpha',\n",
              " 'is_ancestor',\n",
              " 'is_ascii',\n",
              " 'is_bracket',\n",
              " 'is_currency',\n",
              " 'is_digit',\n",
              " 'is_left_punct',\n",
              " 'is_lower',\n",
              " 'is_oov',\n",
              " 'is_punct',\n",
              " 'is_quote',\n",
              " 'is_right_punct',\n",
              " 'is_sent_end',\n",
              " 'is_sent_start',\n",
              " 'is_space',\n",
              " 'is_stop',\n",
              " 'is_title',\n",
              " 'is_upper',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'left_edge',\n",
              " 'lefts',\n",
              " 'lemma',\n",
              " 'lemma_',\n",
              " 'lex',\n",
              " 'lex_id',\n",
              " 'like_email',\n",
              " 'like_num',\n",
              " 'like_url',\n",
              " 'lower',\n",
              " 'lower_',\n",
              " 'morph',\n",
              " 'n_lefts',\n",
              " 'n_rights',\n",
              " 'nbor',\n",
              " 'norm',\n",
              " 'norm_',\n",
              " 'orth',\n",
              " 'orth_',\n",
              " 'pos',\n",
              " 'pos_',\n",
              " 'prefix',\n",
              " 'prefix_',\n",
              " 'prob',\n",
              " 'rank',\n",
              " 'remove_extension',\n",
              " 'right_edge',\n",
              " 'rights',\n",
              " 'sent',\n",
              " 'sent_start',\n",
              " 'sentiment',\n",
              " 'set_extension',\n",
              " 'set_morph',\n",
              " 'shape',\n",
              " 'shape_',\n",
              " 'similarity',\n",
              " 'subtree',\n",
              " 'suffix',\n",
              " 'suffix_',\n",
              " 'tag',\n",
              " 'tag_',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab',\n",
              " 'whitespace_']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(token0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jTTXTqqPgVN",
        "outputId": "6b2f0ba1-190d-4749-da0a-e15826906c54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token0.is_alpha\n",
        "#token0 is alphabetic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27YSL8zrP6HK",
        "outputId": "4fd4320a-6607-4ce9-e452-40b6c9597004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token0.like_num\n",
        "#token0 is numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h-8W0b9hQMiM",
        "outputId": "405391ca-448a-4827-eb2b-523b390ccfe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'two'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token2 = doc[2]\n",
        "token2.text\n",
        "#prints text output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2InLS9QQoZY",
        "outputId": "1cf06f89-3098-4fa7-d856-5f7ed6236e19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token2.like_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFKnhfn2RAtm",
        "outputId": "bc0039fa-7c50-4e04-ad15-c2a822eda23e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "$"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token3 = doc[3]\n",
        "token3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhftf5RYRNSM",
        "outputId": "df0860e5-0b20-4f61-967b-a03e13d6116a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token3.like_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvtUp5i5RP_U",
        "outputId": "e3e62053-6df2-4f32-8090-747bd255f85d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token3.is_currency\n",
        "# token3 is a currency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO2hwGEKRaFS",
        "outputId": "64e42802-4490-4153-951b-72c63d9de027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tony ==> index:  0 is_alpha: True is_punct: False like_num: False is_currency:  False\n",
            "gave ==> index:  1 is_alpha: True is_punct: False like_num: False is_currency:  False\n",
            "two ==> index:  2 is_alpha: True is_punct: False like_num: True is_currency:  False\n",
            "$ ==> index:  3 is_alpha: False is_punct: False like_num: False is_currency:  True\n",
            "to ==> index:  4 is_alpha: True is_punct: False like_num: False is_currency:  False\n",
            "Peter ==> index:  5 is_alpha: True is_punct: False like_num: False is_currency:  False\n"
          ]
        }
      ],
      "source": [
        "# printing a few of the attributes using a function\n",
        "for token in doc:\n",
        "  print(token, \"==>\", \"index: \", token.i, \"is_alpha:\", token.is_alpha,\n",
        "        \"is_punct:\", token.is_punct,\n",
        "        \"like_num:\", token.like_num,\n",
        "        \"is_currency: \", token.is_currency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVvquAO_T813"
      },
      "source": [
        "collect emial id's of students form information doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXeTp18LTkt0",
        "outputId": "fad982aa-4a00-46a2-a584-a279ea053218"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Dayton high school, 8th grade students information\\n',\n",
              " '==================================================\\n',\n",
              " '\\n',\n",
              " 'Name\\tbirth day   \\temail\\n',\n",
              " '-----\\t------------\\t------\\n',\n",
              " 'Virat   5 June, 1882    virat@kohli.com\\n',\n",
              " 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n",
              " 'Serena  24 June, 1998   serena@williams.com \\n',\n",
              " 'Joe      1 May, 1997    joe@root.com']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"students.txt\") as f:\n",
        "  text = f.readlines()\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ViEQFuTvVKgG",
        "outputId": "34e09e2e-52fd-4c59-ac2f-dc52b71a4eb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert into continous text\n",
        "text = ' '.join(text)\n",
        "text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdblxiEnVlRQ",
        "outputId": "86f8892c-0dfc-4786-8776-af300418b810"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['virat@kohli.com',\n",
              " 'maria@sharapova.com',\n",
              " 'serena@williams.com',\n",
              " 'joe@root.com']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc = nlp(text)\n",
        "emails = []\n",
        "# grab all tokens as an array\n",
        "\n",
        "\n",
        "for token in doc:\n",
        "  if token.like_email:\n",
        "    emails.append(token.text)\n",
        "\n",
        "emails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BJ1lSr9XkBg"
      },
      "source": [
        "support in other languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTYz9bR2WD3D",
        "outputId": "c9a9fc8e-6d6d-440b-9224-e39974cdbc75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¡ False False\n",
            "hermano False False\n",
            "! False False\n",
            "5000 False True\n",
            "£ True False\n",
            "fueron False False\n",
            "prestados False False\n",
            ", False False\n",
            "devuélvelos False False\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.blank(\"es\")\n",
        "\n",
        "doc = nlp(\"¡hermano! 5000 £ fueron prestados, devuélvelos\")\n",
        "for token in doc:\n",
        "  print(token, token.is_currency, token.like_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7Ft6WCKaKJX"
      },
      "source": [
        "customizing tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTVyi0leZkOS",
        "outputId": "08d311d1-dfd9-4c01-b3fe-ce82117352c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N74no9eay2_"
      },
      "source": [
        "should give two tokens for gimme hence customize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEFDjseaalaG",
        "outputId": "f8aaeb50-bb52-49d0-f1b7-1529ba689ccb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from spacy.symbols import ORTH\n",
        "\n",
        "nlp.tokenizer.add_special_case(\"gimme\", [\n",
        "                                         {ORTH: \"gim\"},\n",
        "                                         {ORTH: \"me\"},\n",
        "])\n",
        "\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVgManMqcAy-"
      },
      "source": [
        "Sentence tokenization/segmentation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "joYDcj5Wbz2Q",
        "outputId": "94ecb2b0-b3ca-4091-b94f-0a7420a74616"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\kimani\\Documents\\data science\\NLP\\Tokenization_in_Spacy_NLP_Tutorial_For_Beginners_8.ipynb Cell 40'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kimani/Documents/data%20science/NLP/Tokenization_in_Spacy_NLP_Tutorial_For_Beginners_8.ipynb#ch0000038?line=0'>1</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(\u001b[39m\"\u001b[39m\u001b[39mDr. Strange loves pav bhaji of Mumbai. Hulk loves chat of Delhi\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kimani/Documents/data%20science/NLP/Tokenization_in_Spacy_NLP_Tutorial_For_Beginners_8.ipynb#ch0000038?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39msents:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kimani/Documents/data%20science/NLP/Tokenization_in_Spacy_NLP_Tutorial_For_Beginners_8.ipynb#ch0000038?line=2'>3</a>\u001b[0m   \u001b[39mprint\u001b[39m(sentence)\n",
            "File \u001b[1;32mc:\\Users\\kimani\\anaconda3\\lib\\site-packages\\spacy\\tokens\\doc.pyx:889\u001b[0m, in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
          ]
        }
      ],
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of Mumbai. Hulk loves chat of Delhi\")\n",
        "for sentence in doc.sents:\n",
        "  print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10kjkj3lcld8"
      },
      "source": [
        " add a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-uxgQZiccXn",
        "outputId": "8bff9c0c-b27f-47af-a44c-7208c3faa517"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2k_cnoAcjud",
        "outputId": "5552addc-9cf6-4446-8b13-ae3826ec770d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x283b379eec0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp.add_pipe('sentencizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEs8NlFUcwqA",
        "outputId": "9707bc66-e0c0-4ac6-ad4f-ceb77b2a8217"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['sentencizer']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCdRpINfcynb",
        "outputId": "4f062ca6-a00c-4055-85c4-eb684718b9ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dr. Strange loves pav bhaji of Mumbai.\n",
            "Hulk loves chat of Delhi\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of Mumbai. Hulk loves chat of Delhi\")\n",
        "for sentence in doc.sents:\n",
        "  print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCruf4n5dZ_n",
        "outputId": "cdfd91d1-89f8-478f-e009-3c0851b19143"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x283b379eec0>)]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp.pipeline"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Tokenization in Spacy: NLP Tutorial For Beginners - 8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "b5188e894f1af23828e4186655a2a8844c21db8f14cd2bcc058901e4cf69243b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
