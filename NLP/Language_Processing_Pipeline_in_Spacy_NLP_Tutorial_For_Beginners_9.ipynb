{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Processing Pipeline in Spacy: NLP Tutorial For Beginners - 9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# spacy language processing pipelines"
      ],
      "metadata": {
        "id": "u-njRZIoXX7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can get some pre-trained language pipelines that give some components such as tagger, parser, ner free out of the box. Using these components you can detect part of speech, named entities, perform sentence segmentation, etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "uvFb1su5W3Py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "blank nlp pipeline"
      ],
      "metadata": {
        "id": "I6-inn15YFFo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ebk-PUwkWbwt"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klRntJ1fX4El",
        "outputId": "06a61855-819b-4fec-8f3a-df5dde22aee8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain\n",
            "america\n",
            "ate\n",
            "100\n",
            "$\n",
            "of\n",
            "samosa\n",
            ".\n",
            "Then\n",
            "he\n",
            "said\n",
            "I\n",
            "can\n",
            "do\n",
            "this\n",
            "all\n",
            "day\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_61hBmIY1Pg",
        "outputId": "fc6347bd-af92-476c-e686-e2568580e757"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipelines are blank"
      ],
      "metadata": {
        "id": "aobqjq31ZHFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "downloading a trained pipeline"
      ],
      "metadata": {
        "id": "sDkMBg6TZ2wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbCjHVvuZFFI",
        "outputId": "f9157474-fd96-4fee-930b-72f0194344e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32pnt98caFFv",
        "outputId": "8c296958-8738-4db5-c2d8-a884c08c482a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f68e3520e50>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f68e35209f0>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f68e33808d0>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f68e33457d0>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f68e332c0a0>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f68e337aed0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token, \" | \", token.pos_, \" |\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKERr9_2adhE",
        "outputId": "9fb2af13-a430-4595-febe-837af176e23b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain  |  PROPN  | Captain\n",
            "america  |  PROPN  | america\n",
            "ate  |  VERB  | eat\n",
            "100  |  NUM  | 100\n",
            "$  |  NUM  | $\n",
            "of  |  ADP  | of\n",
            "samosa  |  NOUN  | samosa\n",
            ".  |  PUNCT  | .\n",
            "Then  |  ADV  | then\n",
            "he  |  PRON  | he\n",
            "said  |  VERB  | say\n",
            "I  |  PRON  | I\n",
            "can  |  AUX  | can\n",
            "do  |  VERB  | do\n",
            "this  |  PRON  | this\n",
            "all  |  DET  | all\n",
            "day  |  NOUN  | day\n",
            ".  |  PUNCT  | .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "running same code with a blank pipeline"
      ],
      "metadata": {
        "id": "moGS70_mcFfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp1 = spacy.blank(\"en\")\n",
        "\n",
        "doc = nlp1(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token, \" | \", token.pos_, \" |\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IzNPAZybEav",
        "outputId": "200a496e-1fbd-4016-d415-4750dbb1102b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain  |    | \n",
            "america  |    | \n",
            "ate  |    | \n",
            "100  |    | \n",
            "$  |    | \n",
            "of  |    | \n",
            "samosa  |    | \n",
            ".  |    | \n",
            "Then  |    | \n",
            "he  |    | \n",
            "said  |    | \n",
            "I  |    | \n",
            "can  |    | \n",
            "do  |    | \n",
            "this  |    | \n",
            "all  |    | \n",
            "day  |    | \n",
            ".  |    | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named entity recognition"
      ],
      "metadata": {
        "id": "f3XKIRQMcZbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnJ443INcWJr",
        "outputId": "bf80b181-c2a4-48fd-d2e4-bb8e855c1c5a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
            "$45 billion  |  MONEY  |  Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "IqmLdI2nc2-A",
        "outputId": "ed850dfe-c8fd-4320-893d-18c560d286c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Tesla Inc\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is going to acquire twitter for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $45 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "try pipeline in french"
      ],
      "metadata": {
        "id": "avpBrWZted5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"fr_core_news_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "Tl8z49sQdZt9",
        "outputId": "7052ab12-4e10-4a81-d6ca-127475754abe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8f4c0b2c70cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fr_core_news_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m     51\u001b[0m     return util.load_model(\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download fr_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLymqJfMeo4t",
        "outputId": "ccdf21f4-093b-42a3-e022-27001beeeaf3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fr-core-news-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.3.0/fr_core_news_sm-3.3.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-sm==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (0.7.7)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (0.4.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->fr-core-news-sm==3.3.0) (2.0.1)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"fr_core_news_sm\")"
      ],
      "metadata": {
        "id": "Z9ZY7Ofqev7W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc va racheter Twitter pour $45 milliards de dollars\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbFF_kXce4ad",
        "outputId": "d971e62f-32a8-47d3-d458-2330a67859c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc  |  PER  |  Named person or family.\n",
            "Twitter  |  MISC  |  Miscellaneous entities, e.g. events, nationalities, products or works of art\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token, \" | \", token.pos_, \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05fREiVYfJ7r",
        "outputId": "9c6af64c-af81-4e0a-b8ca-8e427a0a8ced"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla  |  PROPN  |  Tesla\n",
            "Inc  |  PROPN  |  Inc\n",
            "va  |  VERB  |  aller\n",
            "racheter  |  VERB  |  racheter\n",
            "Twitter  |  PROPN  |  Twitter\n",
            "pour  |  ADP  |  pour\n",
            "$  |  NOUN  |  dollar\n",
            "45  |  NUM  |  45\n",
            "milliards  |  NOUN  |  milliard\n",
            "de  |  ADP  |  de\n",
            "dollars  |  NOUN  |  dollar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "adding a component into a blank pipeline"
      ],
      "metadata": {
        "id": "d9oIDom5fk8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "doc = nlp(\"Tesla Inc va racheter Twitter pour $45 milliards de dollars\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "id": "rKG8c7v5fhUo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nth printed"
      ],
      "metadata": {
        "id": "tx8ymAtSgDjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "add custom ner"
      ],
      "metadata": {
        "id": "maeR20b8gKo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"ner\", source=source_nlp)\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOc5sFBzgC5G",
        "outputId": "2aa51d9c-ebe7-4ca3-8dbc-756a68d3c49e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ner']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnNHiyVqgXWT",
        "outputId": "6a551de2-eb01-40ef-d490-685f891924c5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
            "$45 billion  |  MONEY  |  Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pMHda1gEgjpT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}